{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e911954a-4f29-4b2e-a9c9-48817d3342de",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Cell bellow will load small preprocessed part of VK dataset with 1% of random users and 1% of most frequent items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3c3de8-016b-496a-8a37-aa6bb451bd4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desor/Desktop/data/VK-LSVD/conda_env/env/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop embedding - item embedding shape: (196277, 64)\n",
      "Item embedding example before normalization [-0.5225   -0.1632    0.133    -0.007618  0.1466    0.3093    0.01971\n",
      " -0.0708    0.02953   0.2052   -0.1664    0.213     0.013504  0.1641\n",
      " -0.2498   -0.146    -0.0669   -0.004204  0.03156  -0.02571  -0.0659\n",
      " -0.1031    0.09924   0.06976   0.10284  -0.0633    0.0561   -0.002018\n",
      "  0.0637    0.03955  -0.0916    0.02654 ]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "subsample_name = 'up0.01_ip0.01'\n",
    "# Original script fores us to use embedding with size 32\n",
    "content_embedding_size = 32\n",
    "# That is suboptimal cause we loose data, I will use 64\n",
    "# content_embedding_size = 64\n",
    "\n",
    "train_interactions_files = [f'subsamples/{subsample_name}/train/week_{i:02}.parquet'\n",
    "                            for i in range(25)]\n",
    "val_interactions_file = [f'subsamples/{subsample_name}/validation/week_25.parquet']\n",
    "\n",
    "metadata_files = ['metadata/users_metadata.parquet',\n",
    "                  'metadata/items_metadata.parquet',\n",
    "                  'metadata/item_embeddings.npz']\n",
    "\n",
    "for file in (train_interactions_files +\n",
    "             val_interactions_file +\n",
    "             metadata_files):\n",
    "    hf_hub_download(\n",
    "        repo_id='deepvk/VK-LSVD', repo_type='dataset',\n",
    "        filename=file, local_dir='VK-LSVD'\n",
    "    )\n",
    "\n",
    "train_interactions = pl.concat([pl.scan_parquet(f'VK-LSVD/{file}')\n",
    "                                for file in train_interactions_files])\n",
    "# Train raw data\n",
    "train_interactions = train_interactions.collect(engine='streaming')\n",
    "# Validataion raw data\n",
    "val_interactions = pl.read_parquet(f'VK-LSVD/{val_interactions_file[0]}')\n",
    "\n",
    "# List of unique users in train dataset\n",
    "train_users = train_interactions.select('user_id').unique()\n",
    "# List of unique items in train dataset\n",
    "train_items = train_interactions.select('item_id').unique()\n",
    "\n",
    "# Metadata of 1% of most frequent videos\n",
    "item_ids = np.load('VK-LSVD/metadata/item_embeddings.npz')['item_id']\n",
    "# VK prearanged embeddings that describe video data\n",
    "item_embeddings = np.load('VK-LSVD/metadata/item_embeddings.npz')['embedding']\n",
    "\n",
    "# Select only items in our subset from global items metadata\n",
    "mask = np.isin(item_ids, train_items.to_numpy())\n",
    "# Leave only train metadata indices\n",
    "item_ids = item_ids[mask]\n",
    "# Leave only train metadata embeddings\n",
    "item_embeddings = item_embeddings[mask]\n",
    "\n",
    "# Here we chose embedding size; In exampe script we crop embedding to 32 positions\n",
    "# That is suboptimal approach, we have full 64 positions, so here we loose useful data\n",
    "# However it is unclear what features lie in second half\n",
    "print(f\"Crop embedding - item embedding shape: {item_embeddings.shape}\")\n",
    "item_embeddings = item_embeddings[:, :content_embedding_size]\n",
    "# Temporary disable normalization to test GMM for class selection\n",
    "print(f\"Item embedding example before normalization {item_embeddings[0]}\")\n",
    "# item_embeddings = item_embeddings / np.linalg.norm(item_embeddings, axis=1).reshape((item_embeddings.shape[0], 1))\n",
    "# print(f\"Item embedding example after normalization {item_embeddings[0]}\")\n",
    "\n",
    "users_metadata = pl.read_parquet('VK-LSVD/metadata/users_metadata.parquet')\n",
    "items_metadata = pl.read_parquet('VK-LSVD/metadata/items_metadata.parquet')\n",
    "\n",
    "users_metadata = users_metadata.join(train_users, on='user_id')\n",
    "items_metadata = items_metadata.join(train_items, on='item_id')\n",
    "items_metadata = items_metadata.join(pl.DataFrame({'item_id': item_ids, \n",
    "                                                   'embedding': item_embeddings}), \n",
    "                                     on='item_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd96f1b-4828-41be-a330-904b48ec5968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100_000, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>age</th><th>gender</th><th>geo</th><th>train_interactions_rank</th></tr><tr><td>u32</td><td>u8</td><td>u8</td><td>u8</td><td>u32</td></tr></thead><tbody><tr><td>136302664</td><td>18</td><td>1</td><td>0</td><td>64701</td></tr><tr><td>347489880</td><td>18</td><td>1</td><td>0</td><td>40800</td></tr><tr><td>200182184</td><td>18</td><td>1</td><td>1</td><td>82233</td></tr><tr><td>202612548</td><td>18</td><td>1</td><td>1</td><td>965</td></tr><tr><td>417607951</td><td>18</td><td>1</td><td>1</td><td>17023</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>220172774</td><td>70</td><td>2</td><td>79</td><td>8146</td></tr><tr><td>310638477</td><td>70</td><td>2</td><td>79</td><td>1363</td></tr><tr><td>361209246</td><td>70</td><td>2</td><td>79</td><td>31077</td></tr><tr><td>368937023</td><td>70</td><td>2</td><td>79</td><td>70482</td></tr><tr><td>455926820</td><td>70</td><td>2</td><td>79</td><td>71443</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100_000, 5)\n",
       "┌───────────┬─────┬────────┬─────┬─────────────────────────┐\n",
       "│ user_id   ┆ age ┆ gender ┆ geo ┆ train_interactions_rank │\n",
       "│ ---       ┆ --- ┆ ---    ┆ --- ┆ ---                     │\n",
       "│ u32       ┆ u8  ┆ u8     ┆ u8  ┆ u32                     │\n",
       "╞═══════════╪═════╪════════╪═════╪═════════════════════════╡\n",
       "│ 136302664 ┆ 18  ┆ 1      ┆ 0   ┆ 64701                   │\n",
       "│ 347489880 ┆ 18  ┆ 1      ┆ 0   ┆ 40800                   │\n",
       "│ 200182184 ┆ 18  ┆ 1      ┆ 1   ┆ 82233                   │\n",
       "│ 202612548 ┆ 18  ┆ 1      ┆ 1   ┆ 965                     │\n",
       "│ 417607951 ┆ 18  ┆ 1      ┆ 1   ┆ 17023                   │\n",
       "│ …         ┆ …   ┆ …      ┆ …   ┆ …                       │\n",
       "│ 220172774 ┆ 70  ┆ 2      ┆ 79  ┆ 8146                    │\n",
       "│ 310638477 ┆ 70  ┆ 2      ┆ 79  ┆ 1363                    │\n",
       "│ 361209246 ┆ 70  ┆ 2      ┆ 79  ┆ 31077                   │\n",
       "│ 368937023 ┆ 70  ┆ 2      ┆ 79  ┆ 70482                   │\n",
       "│ 455926820 ┆ 70  ┆ 2      ┆ 79  ┆ 71443                   │\n",
       "└───────────┴─────┴────────┴─────┴─────────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de533dde-662e-42d5-84ca-2df44646e352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (196_277, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item_id</th><th>author_id</th><th>duration</th><th>train_interactions_rank</th><th>embedding</th></tr><tr><td>u32</td><td>u32</td><td>u8</td><td>u32</td><td>array[f16, 32]</td></tr></thead><tbody><tr><td>1222</td><td>274696</td><td>35</td><td>98839</td><td>[-0.522461, -0.163208, … 0.026535]</td></tr><tr><td>2376</td><td>936009</td><td>9</td><td>97985</td><td>[-0.270752, 0.321533, … 0.064697]</td></tr><tr><td>2425</td><td>219847</td><td>63</td><td>149209</td><td>[-0.505859, -0.174438, … -0.032288]</td></tr><tr><td>5967</td><td>504767</td><td>59</td><td>56611</td><td>[-0.541016, -0.079773, … 0.003593]</td></tr><tr><td>8553</td><td>687320</td><td>28</td><td>142411</td><td>[-0.307129, -0.172974, … 0.035645]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>608049069</td><td>330884</td><td>12</td><td>23765</td><td>[-0.317627, -0.120422, … 0.098633]</td></tr><tr><td>608053295</td><td>946780</td><td>13</td><td>114670</td><td>[-0.522949, -0.110229, … 0.003149]</td></tr><tr><td>608059538</td><td>930725</td><td>5</td><td>155307</td><td>[-0.36792, 0.172363, … 0.067444]</td></tr><tr><td>608061840</td><td>1222813</td><td>59</td><td>64327</td><td>[-0.631348, -0.17749, … 0.011719]</td></tr><tr><td>608065379</td><td>1238991</td><td>20</td><td>188299</td><td>[-0.387695, 0.065491, … -0.06665]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (196_277, 5)\n",
       "┌───────────┬───────────┬──────────┬─────────────────────────┬─────────────────────────────────┐\n",
       "│ item_id   ┆ author_id ┆ duration ┆ train_interactions_rank ┆ embedding                       │\n",
       "│ ---       ┆ ---       ┆ ---      ┆ ---                     ┆ ---                             │\n",
       "│ u32       ┆ u32       ┆ u8       ┆ u32                     ┆ array[f16, 32]                  │\n",
       "╞═══════════╪═══════════╪══════════╪═════════════════════════╪═════════════════════════════════╡\n",
       "│ 1222      ┆ 274696    ┆ 35       ┆ 98839                   ┆ [-0.522461, -0.163208, … 0.026… │\n",
       "│ 2376      ┆ 936009    ┆ 9        ┆ 97985                   ┆ [-0.270752, 0.321533, … 0.0646… │\n",
       "│ 2425      ┆ 219847    ┆ 63       ┆ 149209                  ┆ [-0.505859, -0.174438, … -0.03… │\n",
       "│ 5967      ┆ 504767    ┆ 59       ┆ 56611                   ┆ [-0.541016, -0.079773, … 0.003… │\n",
       "│ 8553      ┆ 687320    ┆ 28       ┆ 142411                  ┆ [-0.307129, -0.172974, … 0.035… │\n",
       "│ …         ┆ …         ┆ …        ┆ …                       ┆ …                               │\n",
       "│ 608049069 ┆ 330884    ┆ 12       ┆ 23765                   ┆ [-0.317627, -0.120422, … 0.098… │\n",
       "│ 608053295 ┆ 946780    ┆ 13       ┆ 114670                  ┆ [-0.522949, -0.110229, … 0.003… │\n",
       "│ 608059538 ┆ 930725    ┆ 5        ┆ 155307                  ┆ [-0.36792, 0.172363, … 0.06744… │\n",
       "│ 608061840 ┆ 1222813   ┆ 59       ┆ 64327                   ┆ [-0.631348, -0.17749, … 0.0117… │\n",
       "│ 608065379 ┆ 1238991   ┆ 20       ┆ 188299                  ┆ [-0.387695, 0.065491, … -0.066… │\n",
       "└───────────┴───────────┴──────────┴─────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3889438c-9b2c-4c94-8146-1bf01f9c5b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_355_927_253, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>place</th><th>platform</th><th>agent</th><th>timespent</th><th>like</th><th>dislike</th><th>share</th><th>bookmark</th><th>click_on_author</th><th>open_comments</th></tr><tr><td>u32</td><td>u32</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td></tr></thead><tbody><tr><td>4862415</td><td>175404824</td><td>0</td><td>0</td><td>0</td><td>48</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>true</td></tr><tr><td>276873582</td><td>97755319</td><td>1</td><td>1</td><td>1</td><td>44</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>434112541</td><td>254862034</td><td>1</td><td>1</td><td>1</td><td>41</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>37377677</td><td>132750843</td><td>1</td><td>1</td><td>1</td><td>8</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>425914526</td><td>163619500</td><td>1</td><td>0</td><td>0</td><td>27</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>309417267</td><td>42883716</td><td>1</td><td>0</td><td>0</td><td>59</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>226669287</td><td>532713837</td><td>1</td><td>0</td><td>0</td><td>17</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>216075342</td><td>115770061</td><td>1</td><td>0</td><td>0</td><td>36</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>509866772</td><td>205500526</td><td>1</td><td>0</td><td>0</td><td>1</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr><tr><td>507446486</td><td>295144879</td><td>1</td><td>0</td><td>0</td><td>7</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_355_927_253, 12)\n",
       "┌───────────┬───────────┬───────┬──────────┬───┬───────┬──────────┬────────────────┬───────────────┐\n",
       "│ user_id   ┆ item_id   ┆ place ┆ platform ┆ … ┆ share ┆ bookmark ┆ click_on_autho ┆ open_comments │\n",
       "│ ---       ┆ ---       ┆ ---   ┆ ---      ┆   ┆ ---   ┆ ---      ┆ r              ┆ ---           │\n",
       "│ u32       ┆ u32       ┆ u8    ┆ u8       ┆   ┆ bool  ┆ bool     ┆ ---            ┆ bool          │\n",
       "│           ┆           ┆       ┆          ┆   ┆       ┆          ┆ bool           ┆               │\n",
       "╞═══════════╪═══════════╪═══════╪══════════╪═══╪═══════╪══════════╪════════════════╪═══════════════╡\n",
       "│ 4862415   ┆ 175404824 ┆ 0     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ true          │\n",
       "│ 276873582 ┆ 97755319  ┆ 1     ┆ 1        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 434112541 ┆ 254862034 ┆ 1     ┆ 1        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 37377677  ┆ 132750843 ┆ 1     ┆ 1        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 425914526 ┆ 163619500 ┆ 1     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ …         ┆ …         ┆ …     ┆ …        ┆ … ┆ …     ┆ …        ┆ …              ┆ …             │\n",
       "│ 309417267 ┆ 42883716  ┆ 1     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 226669287 ┆ 532713837 ┆ 1     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 216075342 ┆ 115770061 ┆ 1     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 509866772 ┆ 205500526 ┆ 1     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "│ 507446486 ┆ 295144879 ┆ 1     ┆ 0        ┆ … ┆ false ┆ false    ┆ false          ┆ false         │\n",
       "└───────────┴───────────┴───────┴──────────┴───┴───────┴──────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9971bb87-8589-477e-8ca0-a9c8aabc60b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100_000, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>470205700</td></tr><tr><td>379558691</td></tr><tr><td>393239373</td></tr><tr><td>176058686</td></tr><tr><td>213504679</td></tr><tr><td>&hellip;</td></tr><tr><td>437706787</td></tr><tr><td>433823280</td></tr><tr><td>172760320</td></tr><tr><td>504110562</td></tr><tr><td>107764864</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100_000, 1)\n",
       "┌───────────┐\n",
       "│ user_id   │\n",
       "│ ---       │\n",
       "│ u32       │\n",
       "╞═══════════╡\n",
       "│ 470205700 │\n",
       "│ 379558691 │\n",
       "│ 393239373 │\n",
       "│ 176058686 │\n",
       "│ 213504679 │\n",
       "│ …         │\n",
       "│ 437706787 │\n",
       "│ 433823280 │\n",
       "│ 172760320 │\n",
       "│ 504110562 │\n",
       "│ 107764864 │\n",
       "└───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d504cb71-5570-41b3-8d76-537f1ac6e5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (196_277, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item_id</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>502206635</td></tr><tr><td>330672826</td></tr><tr><td>360757243</td></tr><tr><td>212351180</td></tr><tr><td>495351156</td></tr><tr><td>&hellip;</td></tr><tr><td>230248039</td></tr><tr><td>583493481</td></tr><tr><td>28424285</td></tr><tr><td>22806726</td></tr><tr><td>194790918</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (196_277, 1)\n",
       "┌───────────┐\n",
       "│ item_id   │\n",
       "│ ---       │\n",
       "│ u32       │\n",
       "╞═══════════╡\n",
       "│ 502206635 │\n",
       "│ 330672826 │\n",
       "│ 360757243 │\n",
       "│ 212351180 │\n",
       "│ 495351156 │\n",
       "│ …         │\n",
       "│ 230248039 │\n",
       "│ 583493481 │\n",
       "│ 28424285  │\n",
       "│ 22806726  │\n",
       "│ 194790918 │\n",
       "└───────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287c7858-787c-49ad-ba18-5cb8e00ea86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_100(submission, intereactions):\n",
    "    final_metric = 0\n",
    "    for j, entry in enumerate(submission.iter_rows(named=True)):\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        iid = entry[\"item_id\"]\n",
    "        for i, uid in enumerate(entry[\"user_id\"]):\n",
    "            row = intereactions.filter((pl.col(\"user_id\") == uid) & (pl.col(\"item_id\") == iid),)\n",
    "            row_arr = np.array([row[\"like\"], row[\"dislike\"], row[\"share\"], row[\"bookmark\"], row[\"click_on_author\"], row[\"open_comments\"]])\n",
    "            idcg += pow(2.0, np.int32(row_arr.any()) - 1) / (np.log2(i + 2))\n",
    "            dcg += np.int32(row_arr.any()) / (np.log2(i + 2))\n",
    "        final_metric += dcg / idcg\n",
    "        if (j % 1000 == 0):\n",
    "            print(final_metric)\n",
    "    return final_metric / submission.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27526599-099b-489c-ad55-beb0caf15069",
   "metadata": {},
   "source": [
    "## Ideas to test\n",
    "### First user preference embedding\n",
    "We should take 100 clips given to us and create several features out of it.\n",
    "First we must found average user embedding. For that we take items that user\n",
    "Have watched and calculate average embedding. Also we may calculate average embedding\n",
    "with videos with which he intereacted most. I.e only liked, shared. \n",
    "And one with wich he don't want to intereact: disliked.\n",
    "\n",
    "Average 100 items embedding: [0.5, xxx, xxx, ..., xxx] - len 64\n",
    "\n",
    "Average liked and shared and watched embedding: [xxx, xxx, xxx, ..., xxx] - len 64\n",
    "\n",
    "Average disliked embedding: [xxx, xxx, xxx, ..., xxx] - len 64\n",
    "\n",
    "Problem with idea - I don't have guarantee that average embedding will hold some real meaning.\n",
    "Hope that tree will filter meaningless embedding positions.\n",
    "### Second idea use HSNW to cluster the user pseudoclass into \"abstract bubbles\" and later average this bubbles\n",
    "Find all clips watched by some user and split them into interest.Then for each interest we will have separate average embedding\n",
    "\n",
    "This approach already exists and called Gaussian Mixture GM\n",
    "\n",
    "After we split dataset to number of classes we must calculate classes for each user.\n",
    "\n",
    "Later we must use XGBoost to build trees that will predict users for given item based on created labels, classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315b1ab-f275-4c4e-80b5-2498b736f958",
   "metadata": {},
   "source": [
    "### First idea realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62581e1b-030e-47e0-a696-84d0e6362ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_users)\n",
    "result = pl.DataFrame({\"user_id\": np.uint32(0), \"embedding\": [np.zeros(64, dtype=np.float32)]})\n",
    "# print(result)\n",
    "for tu in train_users.to_numpy():\n",
    "    # print(tu)\n",
    "    mask = np.isin(train_interactions[\"user_id\"], np.asarray([tu,]))\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    user_watched_items = train_interactions.filter(mask)\n",
    "    all_unique_watched_items = user_watched_items[\"item_id\"].unique()\n",
    "    mask = np.isin(item_ids, all_unique_watched_items.to_numpy())\n",
    "    watched_item_ids_within_all = item_ids[mask]\n",
    "    watched_item_embeddings_within_all = item_embeddings[mask]\n",
    "    # TODO(d-desiatkin): Here we must add normalization, cause extended embedding is not normalized\n",
    "    average_embedding = watched_item_embeddings_within_all.mean(axis=0)\n",
    "    single_user_processing_result = pl.DataFrame({\"user_id\": tu, \"embedding\": [average_embedding]})\n",
    "    result = result.extend(single_user_processing_result)\n",
    "result = result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611e429-ccb6-4344-8357-c845bdb46bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"average_user_embedding.npy\", result, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2451ce-a96c-4164-ac3f-2784027c27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_metadata = users_metadata.join(result, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6136d-e0f7-47e6-9041-da226d9dfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c65999-19be-4631-a239-136b45b50505",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914c2fd-07dc-4286-88b5-b9dacf955a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    return 1 - cosine_similarity(a, b)\n",
    "\n",
    "def length_simmilarity(a,b):\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    similarity = min(norm_a, norm_b) / max(norm_a, norm_b)\n",
    "    return similarity\n",
    "\n",
    "def total_simmilarity(a,b):\n",
    "    first = cosine_similarity(a,b)\n",
    "    second = length_simmilarity(a,b)\n",
    "    # Angle is 80% and Distance 20% of final simmilarity \n",
    "    return first * 0.8 + second * 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34347857-2b12-4176-8322-7bf62f0adee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pl.DataFrame({\"item_id\": np.uint32(0), \"user_id\": [np.zeros(100, dtype=np.uint32)]})\n",
    "for item_entry in items_metadata.iter_rows(named=True):\n",
    "    simmilarity_list = []\n",
    "    for user_entry in users_metadata.iter_rows(named=True):\n",
    "        simmilarity_list.append([user_entry[\"user_id\"], cosine_distance(item_entry[\"embedding\"], user_entry[\"embedding\"])])\n",
    "    simmilarity_list = sorted(simmilarity_list, key=lambda entry: entry[1])\n",
    "    closest_user_ids = np.array([x[0] for x in simmilarity_list[:100]], dtype=np.uint32)\n",
    "    single_item_processing_result = pl.DataFrame({\"item_id\": np.uint32(item_entry[\"item_id\"]), \"user_id\": [closest_user_ids]})\n",
    "    result = result.extend(single_item_processing_result)\n",
    "result = result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739d4a3-4e56-45a8-addd-22b29da071c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7cc48-be3b-4d53-9da7-ad81795cdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"embeedding_similarity_based_submission.npy\", result, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61f66b-ba5d-496d-8c6c-1a15c997f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load(\"embeedding_similarity_based_submission.npy\", allow_pickle=True)\n",
    "result = pl.DataFrame({\"item_id\": tmp.T[0].astype(np.uint32), \"user_id\": tmp.T[1].tolist()})\n",
    "result.write_parquet('submission.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1907794-63ea-4824-9f22-6553f3b80236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_100(result, train_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4315a72-28db-4e74-b62d-e64b7c527735",
   "metadata": {},
   "source": [
    "### Second Idea Realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2c924e-1ca7-49e2-9ebf-fb8d5ecdcc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters passed to constructor:  space=cosine, dim=32\n",
      "Index construction: M=640, ef_construction=4000\n",
      "Index size is 196277 and index capacity is 196277\n",
      "Search speed/quality trade-off parameter: ef=1000\n"
     ]
    }
   ],
   "source": [
    "import hnswlib\n",
    "import pickle\n",
    "\n",
    "dim = 32\n",
    "# num_elements = 10000\n",
    "num_elements = item_embeddings.shape[0]\n",
    "\n",
    "# Aparantly algorythm requires indices...\n",
    "# ids = np.arange(num_elements)\n",
    "\n",
    "# Declaring index\n",
    "p = hnswlib.Index(space = 'cosine', dim = dim) # possible options are l2, cosine or ip\n",
    "\n",
    "# Initializing index - the maximum number of elements should be known beforehand\n",
    "p.init_index(max_elements = num_elements, ef_construction = 4000, M = 640)\n",
    "\n",
    "# Element insertion (can be called several times):\n",
    "p.add_items(item_embeddings)\n",
    "\n",
    "# Controlling the recall by setting ef:\n",
    "p.set_ef(1000) # ef should always be > k\n",
    "\n",
    "# Query dataset, k - number of the closest elements (returns 2 numpy arrays)\n",
    "labels, distances = p.knn_query(item_embeddings[1000:1010], k = 500)\n",
    "\n",
    "# Index objects support pickling\n",
    "# WARNING: serialization via pickle.dumps(p) or p.__getstate__() is NOT thread-safe with p.add_items method!\n",
    "# Note: ef parameter is included in serialization; random number generator is initialized with random_seed on Index load\n",
    "p_copy = pickle.loads(pickle.dumps(p)) # creates a copy of index p using pickle round-trip\n",
    "\n",
    "### Index parameters are exposed as class properties:\n",
    "print(f\"Parameters passed to constructor:  space={p_copy.space}, dim={p_copy.dim}\") \n",
    "print(f\"Index construction: M={p_copy.M}, ef_construction={p_copy.ef_construction}\")\n",
    "print(f\"Index size is {p_copy.element_count} and index capacity is {p_copy.max_elements}\")\n",
    "print(f\"Search speed/quality trade-off parameter: ef={p_copy.ef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3edca5-addb-4780-a67c-93621a41ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fbcced-51a3-422f-8026-631ac692a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=128,\n",
    "                     covariance_type=\"full\",\n",
    "                     tol=1e-6,\n",
    "                     reg_covar=1e-16,\n",
    "                     n_init=1, \n",
    "                     max_iter=2000,\n",
    "                     init_params=\"k-means++\",\n",
    "                     random_state=1094).fit(item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66ea844-d7a1-480a-bdf4-41033bdb460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score lower bound: 32.40050297306434\n",
      "Number of iterations to converge: 641\n",
      "{'covariance_type': 'full', 'init_params': 'k-means++', 'max_iter': 2000, 'means_init': None, 'n_components': 128, 'n_init': 1, 'precisions_init': None, 'random_state': 1094, 'reg_covar': 1e-16, 'tol': 1e-06, 'verbose': 0, 'verbose_interval': 10, 'warm_start': False, 'weights_init': None}\n",
      "[[-0.41019333  0.22170685  0.31923749  0.07133626  0.09925637 -0.0421611\n",
      "  -0.04554408 -0.0899527   0.10958078 -0.06040252  0.04602672 -0.01733871\n",
      "  -0.00628473 -0.01694732 -0.105821    0.05195312 -0.01966997 -0.0652695\n",
      "  -0.00567655 -0.01537108  0.06947336  0.07542811  0.04550196 -0.03104853\n",
      "  -0.04413151  0.00611915 -0.02442662 -0.01587331 -0.05129029  0.02467013\n",
      "   0.05349485 -0.00157624]]\n",
      "[[[ 0.01695752  0.00250496  0.00333141 ...  0.00186054 -0.000286\n",
      "   -0.00082551]\n",
      "  [ 0.00250496  0.01306879 -0.00240423 ...  0.00191387 -0.0026256\n",
      "   -0.00021778]\n",
      "  [ 0.00333141 -0.00240423  0.01233728 ... -0.00093395  0.00072251\n",
      "   -0.00242764]\n",
      "  ...\n",
      "  [ 0.00186054  0.00191387 -0.00093395 ...  0.00749988 -0.00158749\n",
      "    0.00056623]\n",
      "  [-0.000286   -0.0026256   0.00072251 ... -0.00158749  0.0051299\n",
      "    0.00035389]\n",
      "  [-0.00082551 -0.00021778 -0.00242764 ...  0.00056623  0.00035389\n",
      "    0.00813837]]]\n"
     ]
    }
   ],
   "source": [
    "if gm.converged_:\n",
    "    print(f\"Score lower bound: {gm.lower_bound_}\")\n",
    "    print(f\"Number of iterations to converge: {gm.n_iter_}\")\n",
    "else:\n",
    "    print(\"Error! Gaussian Mixture not converged!\")\n",
    "print(gm.get_params())\n",
    "print(gm.means_[:1])\n",
    "print(gm.covariances_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa271e1d-4599-4497-93d0-d7e777d0de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gaussian_mixture_128_full.pickle', 'wb') as f:\n",
    "    pickle.dump(gm, f, protocol=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeed17c-a577-4ef2-9ade-3973af401093",
   "metadata": {},
   "source": [
    "### Second Idea Results\n",
    "\n",
    "[x] 64  components - spherical - final loss: 25.78482731680628 // Powers of two\n",
    "\n",
    "[x] 123 components - spherical - final loss: 26.612402741531618 // Lucas\n",
    "\n",
    "[x] 128 components - spherical - final loss: 26.66317279508462 // Powers of two\n",
    "\n",
    "[x] 144 components - spherical - final loss: 26.822238865843392 // Fibonacchi\n",
    "\n",
    "[x] 199 components - spherical - final loss: 27.235624615038315 // Lucas\n",
    "\n",
    "[x] 233 components - spherical - final loss: 27.44773975338467 // Fibonacchi\n",
    "\n",
    "[x] 377 components - spherical - final loss: 28.065711959610123 // Fibonacchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e133497f-a587-4056-8e6f-33b65db3e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gaussian_mixture_128_full.pickle', 'rb') as f:\n",
    "    gm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f60ffe-7d8d-4579-a698-fb7f881853ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pl.DataFrame({\"user_id\": np.uint32(0)})\n",
    "for i in range(128):\n",
    "    tmp_subres = pl.DataFrame({\"user_id\": np.uint32(0), f\"{i}\": np.float64(0.0)})\n",
    "    result = result.join(tmp_subres, on='user_id')\n",
    "\n",
    "for counter, tu in enumerate(train_users.to_numpy()):\n",
    "    # print(tu)\n",
    "    mask = np.isin(train_interactions[\"user_id\"], np.asarray([tu,]))\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    user_watched_items = train_interactions.filter(mask)\n",
    "    all_unique_watched_items = user_watched_items[\"item_id\"].unique()\n",
    "    mask = np.isin(item_ids, all_unique_watched_items.to_numpy())\n",
    "    watched_item_ids_within_all = item_ids[mask]\n",
    "    watched_item_embeddings_within_all = item_embeddings[mask]\n",
    "    labels = gm.predict(watched_item_embeddings_within_all)\n",
    "    probability = gm.predict_proba(watched_item_embeddings_within_all)\n",
    "    single_user_processing_result = pl.DataFrame({\"user_id\": tu})\n",
    "    for i in range(128):\n",
    "        indices = np.where(labels == i)\n",
    "        selected_prob = probability[indices]\n",
    "        if (selected_prob.size == 0): \n",
    "            mean_prob = np.float64(0.0)\n",
    "        else:\n",
    "            mean_prob = (selected_prob).mean()\n",
    "        tmp_subres = pl.DataFrame({\"user_id\": tu, f\"{i}\": mean_prob})\n",
    "        single_user_processing_result = single_user_processing_result.join(tmp_subres, on='user_id')\n",
    "    result = result.extend(single_user_processing_result)\n",
    "    if(counter == 10):\n",
    "        result.write_parquet('user_classes_checkpoint.parquet')\n",
    "        break\n",
    "result = result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27580c3-2704-4b3c-bc6e-a2e5a1a3169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My code optimised by Yandex AI assistant. Smart him... AI me: 1-0.\n",
    "# Read and learn how to use polars efficiently... And write smth in python for God Sake... It could be a game\n",
    "# Assume gm, train_users, train_interactions, item_embeddings, and item_ids are defined.\n",
    "# We also assume 'result' is initialized correctly (e.g., result = pl.DataFrame()).\n",
    "\n",
    "item_ids = train_items[\"item_id\"].to_numpy()\n",
    "\n",
    "# 1. Pre-calculate GMM probabilities for all items\n",
    "all_item_labels = gm.predict(item_embeddings)\n",
    "all_item_probabilities = gm.predict_proba(item_embeddings)\n",
    "num_components = all_item_probabilities.shape[1] # Should be 128\n",
    "\n",
    "# Create a Polars DataFrame mapping every item_id to its GMM results\n",
    "item_gmm_results = pl.DataFrame({\n",
    "    \"item_id\": item_ids,\n",
    "    \"label\": all_item_labels,\n",
    "})\n",
    "# Append probability columns efficiently using numpy to Polars conversion\n",
    "prob_df = pl.DataFrame(all_item_probabilities, schema={str(i): pl.Float64 for i in range(num_components)})\n",
    "item_gmm_results = pl.concat([item_gmm_results, prob_df], how=\"horizontal\")\n",
    "\n",
    "# 2. Iterate through users and aggregate results using efficient Polars operations\n",
    "user_results_list = []\n",
    "checkpoint_counter = 0\n",
    "\n",
    "# Limit the loop iteration for this specific optimization example (original code had a break condition)\n",
    "for tu in train_users[\"user_id\"].to_numpy():\n",
    "    # Filter user interactions efficiently using Polars' native filtering\n",
    "    user_watched_items_df = train_interactions.filter(\n",
    "        pl.col(\"user_id\") == tu\n",
    "    )\n",
    "\n",
    "    if user_watched_items_df.is_empty():\n",
    "        continue\n",
    "    \n",
    "    # Use Polars join to link watched items with their GMM probabilities\n",
    "    # This is much faster than repeated numpy mask creation and filtering\n",
    "    user_items_with_probs = user_watched_items_df.join(\n",
    "        item_gmm_results, on=\"item_id\", how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    # Calculate the mean probability for each component in a single aggregation step\n",
    "    # The resulting dataframe will have one row for the user, and N columns for the means\n",
    "    mean_probs_df = user_items_with_probs.group_by(\"user_id\").agg(\n",
    "        [pl.mean(str(i)).alias(str(i)) for i in range(num_components)]\n",
    "    )\n",
    "    \n",
    "    user_results_list.append(mean_probs_df)\n",
    "\n",
    "    checkpoint_counter += 1\n",
    "    if checkpoint_counter == 10000:\n",
    "        # Checkpoint logic (if needed)\n",
    "        pl.concat(user_results_list).write_parquet(f'user_embeddings_checkpoints/user_classes_checkpoint_{checkpoint_counter}.parquet')\n",
    "\n",
    "# 3. Combine all results outside the loop\n",
    "# This avoids the slow `result.extend(single_user_processing_result)` inside the loop\n",
    "result = pl.concat(user_results_list)\n",
    "# result = result[1:] # The original code had this. If you initialized 'result' as empty, you might not need this line.\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c668a2-c0f3-41f5-bb61-d17fddc2fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.glimpse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67765b-788a-4753-a76b-b3b403ab789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write_parquet(\"calculated_user_classes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d98b6-08bc-477a-afca-6d24217f6a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
